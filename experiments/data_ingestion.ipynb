{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_path: Path\n",
    "    unzip_dir: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: Path\n",
    "    ALL_REQUIRED_FILES: list\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    tokenizer_name: str\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_ckpt: Path\n",
    "    num_train_epochs: int\n",
    "    warmup_steps: int\n",
    "    per_device_train_batch_size: int\n",
    "    weight_decay: float\n",
    "    logging_steps: int\n",
    "    evaluation_strategy: str\n",
    "    eval_steps: int\n",
    "    save_steps: float\n",
    "    gradient_accumulation_steps: int\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_path: Path\n",
    "    tokenizer_path: Path\n",
    "    metric_file_name: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from src.utils import read_yaml, get_size\n",
    "from src.logger import logging\n",
    "from src.exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'artifacts', 'data_ingestion.ipynb', 'logs', 'text_summerization.ipynb']\n",
      "[2023-07-19 22:39:02,225] 23 root - INFO - Yaml Config file successfully loaded from path: ..\\config\\config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'artifacts/data_ingestion'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=read_yaml(Path(f'../{CONFIG_FILE_PATH}'))\n",
    "h.data_ingestion.root_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_file_path=Path(f'../{CONFIG_FILE_PATH}'),\n",
    "    param_file_path=Path(f'../{PARAMS_FILE_PATH}')) -> None:\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(param_file_path)\n",
    "\n",
    "        os.makedirs(self.config.artifacts_root, exist_ok=True)\n",
    "    \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "        os.makedirs(config.root_dir, exist_ok=True)\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_path=config.local_data_path,\n",
    "            unzip_dir=config.unzip_dir \n",
    "        )\n",
    "        return data_ingestion_config\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        os.makedirs(config.root_dir, exist_ok=True)\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            STATUS_FILE=config.STATUS_FILE,\n",
    "            ALL_REQUIRED_FILES=config.ALL_REQUIRED_FILES \n",
    "        )\n",
    "        return data_validation_config\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        os.makedirs(config.root_dir, exist_ok=True)\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            tokenizer_name=config.tokenizer_name\n",
    "        )\n",
    "        return data_transformation_config\n",
    "    \n",
    "    def get_model_trainer_config(self):\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.TrainingArguments\n",
    "        os.makedirs(config.root_dir, exist_ok=True)\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            model_ckpt = config.model_ckpt,\n",
    "            num_train_epochs = params.num_train_epochs,\n",
    "            warmup_steps = params.warmup_steps,\n",
    "            per_device_train_batch_size = params.per_device_train_batch_size,\n",
    "            weight_decay = params.weight_decay,\n",
    "            logging_steps = params.logging_steps,\n",
    "            evaluation_strategy = params.evaluation_strategy,\n",
    "            eval_steps = params.evaluation_strategy,\n",
    "            save_steps = params.save_steps,\n",
    "            gradient_accumulation_steps = params.gradient_accumulation_steps\n",
    "        )\n",
    "        return model_trainer_config\n",
    "    \n",
    "    def get_model_evaluation_config(self):\n",
    "        config = self.config.model_evaluation\n",
    "        os.makedirs(config.root_dir, exist_ok=True)\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            model_ckpt=config.model_ckpt\n",
    "        )\n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_dataset(self):\n",
    "        if not os.path.exists(self.config.local_data_path):\n",
    "            file, header = request.urlretrieve(url=self.config.source_URL,\n",
    "                                               filename=self.config.local_data_path)\n",
    "            logging.info(f\"{file} successfully downloaded! Info: \\n{header}\")\n",
    "        else:\n",
    "            logging.info(f\"File already exists of size: {get_size(Path(self.config.local_data_path))} KB\")\n",
    "\n",
    "    def extract_zip_file(self, unzip_path=None):\n",
    "        \"\"\"Extract zip file to specified path\n",
    "\n",
    "        Args:\n",
    "            unzip_path: str, optional\n",
    "                The path to extract the zip file to. If not provided, it defaults to `self.config.unzip_dir`.\n",
    "        \"\"\"\n",
    "        if unzip_path is None:\n",
    "            unzip_path = self.config.unzip_dir\n",
    "        try:\n",
    "            os.makedirs(unzip_path, exist_ok=True)\n",
    "            with zipfile.ZipFile(self.config.local_data_path, 'r') as zip_fp:\n",
    "                zip_fp.extractall(unzip_path)\n",
    "                logging.info(\"Dataset successfully extracted.\")\n",
    "        except CustomException as err:\n",
    "            logging.warn(f\"Error while extracting file path: {unzip_path}\")\n",
    "            logging.error(f\"Error explaination: {err}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig) -> None:\n",
    "        self.config = config\n",
    "    \n",
    "    def validate_files(self):\n",
    "        try:\n",
    "            validation_status = False\n",
    "            all_files = os.listdir(os.path.join(\"artifacts\", \"data_ingestion\", \"samsum_dataset\"))\n",
    "            for file in all_files:\n",
    "                if file not in self.config.ALL_REQUIRED_FILES:\n",
    "                    validation_status = False\n",
    "                    with open(self.config.STATUS_FILE, 'w') as fp:\n",
    "                        fp.write(f\"Validation status of {file}: {validation_status}\")\n",
    "                else:\n",
    "                    validation_status = True\n",
    "                    with open(self.config.STATUS_FILE, 'w') as fp:\n",
    "                        fp.write(f\"Validation status of {file}: {validation_status}\")\n",
    "                logging.info(f\"{file} Files validation Success. VALIDATION_STATUS: {validation_status}\")\n",
    "            return validation_status\n",
    "        \n",
    "        except Exception as err:\n",
    "            logging.warn(f\"Cannot validate due to error: \\n{err}\")\n",
    "            raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sabinmc\\Desktop\\New program Practrice\\Python\\ml and dl\\Text Summerization\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.9.10)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name, use_fast=False)\n",
    "    \n",
    "    def convert_to_features(self, batch_data):\n",
    "        # Tokenize the dialogue in the batch using the tokenizer\n",
    "        input_encodings = self.tokenizer(batch_data['dialogue'], max_length=1024, truncation=True)\n",
    "\n",
    "        # Tokenize the summary in the batch using the tokenizer as the target tokenizer\n",
    "        with self.tokenizer.as_target_tokenizer():\n",
    "            target_encodings = self.tokenizer(batch_data['summary'], max_length=128, truncation=True)\n",
    "\n",
    "        # Return the converted features as a dictionary\n",
    "        return {\n",
    "            'input_ids': input_encodings['input_ids'],         # Input token IDs\n",
    "            'attention_mask': input_encodings['attention_mask'],  # Attention mask\n",
    "            'labels': target_encodings['input_ids']             # Target token IDs for the model's training\n",
    "        }\n",
    "    \n",
    "    def get_tokenizer(self):\n",
    "        return self.tokenizer\n",
    "    \n",
    "    def convert(self):\n",
    "        dataset_samsum = load_from_disk(self.config.data_path)\n",
    "        dataset_samsum_pt = dataset_samsum.map(self.convert_to_features, batched=True)\n",
    "        logging.info(\"Converting dataset in batch\")\n",
    "        dataset_samsum_pt.save_to_disk(os.path.join(self.config.root_dir, \"samsum_dataset\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train(self, tokenizer=None):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        logging.info(f\">>>>>>>> Model trainer initiated using {device} <<<<<<<<<<<\")\n",
    "        prev_time = time.time()\n",
    "\n",
    "        if tokenizer is None:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(self.config.model_ckpt)\n",
    "        model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_ckpt).to(device)\n",
    "        seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)\n",
    "        \n",
    "        #loading data \n",
    "        dataset_samsum_pt = load_from_disk(self.config.data_path)\n",
    "\n",
    "        trainer_args = TrainingArguments(\n",
    "            output_dir=self.config.root_dir, \n",
    "            num_train_epochs=self.config.num_train_epochs, \n",
    "            warmup_steps=self.config.warmup_steps,\n",
    "            per_device_train_batch_size=self.config.per_device_train_batch_size, per_device_eval_batch_size=self.config.per_device_train_batch_size,\n",
    "            weight_decay=self.config.weight_decay, \n",
    "            logging_steps=self.config.logging_steps,\n",
    "            evaluation_strategy=self.config.evaluation_strategy, \n",
    "            eval_steps=self.config.eval_steps, \n",
    "            save_steps=1e6,\n",
    "            gradient_accumulation_steps=self.config.gradient_accumulation_steps\n",
    "        ) \n",
    "\n",
    "        trainer = Trainer(model=model_pegasus, \n",
    "                          args=trainer_args,\n",
    "                          tokenizer=tokenizer, \n",
    "                          data_collator=seq2seq_data_collator,\n",
    "                          train_dataset=dataset_samsum_pt[\"train\"], \n",
    "                          eval_dataset=dataset_samsum_pt[\"validation\"])\n",
    "        logging.info(\"Model traineding started......\")\n",
    "        trainer.train()\n",
    "        current_time = time.time()\n",
    "\n",
    "        logging.info(f\"Model trained Successfully in {current_time-prev_time:%.2f} sec\")\n",
    "\n",
    "        ## Save model\n",
    "        model_pegasus.save_pretrained(os.path.join(self.config.root_dir,\"pegasus-samsum-model\"))\n",
    "        ## Save tokenizer\n",
    "        tokenizer.save_pretrained(os.path.join(self.config.root_dir,\"tokenizer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, config: ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def generate_batch_sized_chunks(self, list_of_elements, batch_size):\n",
    "        \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
    "        Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "        for i in range(0, len(list_of_elements), batch_size):\n",
    "            yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "    def evaluate(self, device=None):\n",
    "        if device not in [\"cpu\", \"cuda\"]:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.tokenizer_path, use_fast=False)\n",
    "        model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_path).to(device)\n",
    "       \n",
    "        #loading data \n",
    "        dataset_samsum_pt = load_from_disk(self.config.data_path)\n",
    "        rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "  \n",
    "        # rouge_metric = load_metric('rouge')\n",
    "\n",
    "        # score = self.calculate_metric_on_test_ds(\n",
    "        # dataset_samsum_pt['test'][0:10], rouge_metric, model_pegasus, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary='summary'\n",
    "        #     )\n",
    "\n",
    "        # rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
    "        rouge_dict={}\n",
    "        df = pd.DataFrame(rouge_dict, index=['pegasus'] )\n",
    "        df.to_csv(self.config.metric_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main running code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'artifacts', 'data_ingestion.ipynb', 'logs', 'text_summerization.ipynb']\n",
      "[2023-07-19 22:40:24,339] 23 root - INFO - Yaml Config file successfully loaded from path: ..\\config\\config.yaml\n",
      "['.ipynb_checkpoints', 'artifacts', 'data_ingestion.ipynb', 'logs', 'text_summerization.ipynb']\n",
      "[2023-07-19 22:40:24,349] 23 root - INFO - Yaml Config file successfully loaded from path: ..\\params.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]c:\\Users\\sabinmc\\Desktop\\New program Practrice\\Python\\ml and dl\\Text Summerization\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-19 22:42:01,857] 28 root - INFO - Converting dataset in batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-19 22:42:01,928] 7 root - INFO - >>>>>>>> Model trainer initiated using cpu <<<<<<<<<<<\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[39m# model_evaluation_config.evaluate()\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mraise\u001b[39;00m err\n",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m model_trainer_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_model_trainer_config()\n\u001b[0;32m     11\u001b[0m model_trainer_config \u001b[39m=\u001b[39m ModelTrainer(config\u001b[39m=\u001b[39mmodel_trainer_config)\n\u001b[1;32m---> 12\u001b[0m model_trainer_config\u001b[39m.\u001b[39;49mtrain(tokenizer\u001b[39m=\u001b[39;49mtokenizer)\n\u001b[0;32m     14\u001b[0m model_evaluation_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_model_evaluation_config()\n\u001b[0;32m     15\u001b[0m model_evaluation_config \u001b[39m=\u001b[39m ModelEvaluation(config\u001b[39m=\u001b[39mmodel_evaluation_config)\n",
      "Cell \u001b[1;32mIn[12], line 18\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[1;34m(self, tokenizer)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m#loading data \u001b[39;00m\n\u001b[0;32m     16\u001b[0m dataset_samsum_pt \u001b[39m=\u001b[39m load_from_disk(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_path)\n\u001b[1;32m---> 18\u001b[0m trainer_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m     19\u001b[0m     output_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mroot_dir, \n\u001b[0;32m     20\u001b[0m     num_train_epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_train_epochs, \n\u001b[0;32m     21\u001b[0m     warmup_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mwarmup_steps,\n\u001b[0;32m     22\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mper_device_train_batch_size, per_device_eval_batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mper_device_train_batch_size,\n\u001b[0;32m     23\u001b[0m     weight_decay\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mweight_decay, \n\u001b[0;32m     24\u001b[0m     logging_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mlogging_steps,\n\u001b[0;32m     25\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mevaluation_strategy, \n\u001b[0;32m     26\u001b[0m     eval_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49meval_steps, \n\u001b[0;32m     27\u001b[0m     save_steps\u001b[39m=\u001b[39;49m\u001b[39m1e6\u001b[39;49m,\n\u001b[0;32m     28\u001b[0m     gradient_accumulation_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mgradient_accumulation_steps\n\u001b[0;32m     29\u001b[0m ) \n\u001b[0;32m     31\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model\u001b[39m=\u001b[39mmodel_pegasus, \n\u001b[0;32m     32\u001b[0m                   args\u001b[39m=\u001b[39mtrainer_args,\n\u001b[0;32m     33\u001b[0m                   tokenizer\u001b[39m=\u001b[39mtokenizer, \n\u001b[0;32m     34\u001b[0m                   data_collator\u001b[39m=\u001b[39mseq2seq_data_collator,\n\u001b[0;32m     35\u001b[0m                   train_dataset\u001b[39m=\u001b[39mdataset_samsum_pt[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m     36\u001b[0m                   eval_dataset\u001b[39m=\u001b[39mdataset_samsum_pt[\u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     37\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mModel traineding started......\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m<string>:111\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, xpu_backend)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sabinmc\\Desktop\\New program Practrice\\Python\\ml and dl\\Text Summerization\\venv\\lib\\site-packages\\transformers\\training_args.py:1227\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1225\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m--logging_steps must be an integer if bigger than 1: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogging_steps\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogging_steps \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogging_steps)\n\u001b[1;32m-> 1227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_strategy \u001b[39m==\u001b[39m IntervalStrategy\u001b[39m.\u001b[39mSTEPS \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_steps \u001b[39m>\u001b[39;49m \u001b[39m1\u001b[39;49m:\n\u001b[0;32m   1228\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_steps \u001b[39m!=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_steps):\n\u001b[0;32m   1229\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m--eval_steps must be an integer if bigger than 1: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_steps\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.convert()\n",
    "    tokenizer = data_transformation.get_tokenizer()\n",
    "\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer_config.train(tokenizer=tokenizer)\n",
    "\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    model_evaluation_config = ModelEvaluation(config=model_evaluation_config)\n",
    "    # model_evaluation_config.evaluate()\n",
    "except Exception as err:\n",
    "    raise err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
